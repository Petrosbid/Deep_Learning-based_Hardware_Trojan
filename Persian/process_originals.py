#
# process_originals.py
# (Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù… Ø¯Ø± original_designs)
#
import os
import json
import glob
import time
import networkx as nx
import pickle  # <--- + ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ pickle
from typing import Tuple

# ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† ØªÙˆØ§Ø¨Ø¹ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø²Ø§
import netlist_parser
import phase1_graph_utils


def process_original_file(netlist_path: str) -> Tuple[bool, str]:
    """
    ÛŒÚ© ÙØ§ÛŒÙ„ .v Ø³Ø§Ù„Ù… Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ ÙØ§ÛŒÙ„ gpickle. Ùˆ json. Ù…Ø±Ø¨ÙˆØ·Ù‡â€ŒØ§Ø´ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    try:
        # --- 1. ØªØ¹Ø±ÛŒÙ Ù†Ø§Ù…â€ŒÙ‡Ø§ ---
        base_name = os.path.basename(netlist_path)
        circuit_name = base_name.replace('.v', '')
        dir_name = os.path.dirname(netlist_path)
        log_path = ""  # Ù…Ø³ÛŒØ± Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±
        json_output_file = os.path.join(dir_name, base_name.replace('.v', '_traces.json'))
        graph_output_file = os.path.join(dir_name, base_name.replace('.v', '_pin_graph.gpickle'))

        # --- 2. Ø§Ø¬Ø±Ø§ÛŒ Ø®Ø· Ù„ÙˆÙ„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ ---

        # ÙØ§Ø² 0: Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù†
        trojan_names = netlist_parser.parse_trojan_log(log_path)
        netlist = netlist_parser.parse_netlist(netlist_path, trojan_names)
        if netlist is None:
            return (False, "Parse Error: Netlist is empty or failed to parse")

        # ÙØ§Ø² 1: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ú¯Ø±Ø§Ù
        pin_graph = phase1_graph_utils.convert_to_pin_graph(netlist)

        # --- 3. (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø±Ø§Ù Ø±ÙˆÛŒ Ø¯ÛŒØ³Ú© ---
        try:
            # - nx.write_gpickle(pin_graph, graph_output_file)
            with open(graph_output_file, 'wb') as f:  # <--- + Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„Øª Ù†ÙˆØ´ØªÙ† Ø¨Ø§ÛŒÙ†Ø±ÛŒ
                pickle.dump(pin_graph, f)  # <--- + Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² pickle.dump
        except Exception as e:
            return (False, f"Graph Save Error: {e}")
        # -------------------------------------

        # ÙØ§Ø² 1: (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§
        net_blocks = phase1_graph_utils.generate_netlist_blocks(pin_graph, logic_level=4)

        # ÙØ§Ø² 1: (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø¯ÛŒØ§Ø¨ÛŒâ€ŒÙ‡Ø§
        all_traces_dict = phase1_graph_utils.extract_pcp_traces(net_blocks)

        # --- 4. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ (Ù‡Ù…Ù‡ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨ 0) ---
        labeled_trace_data = []
        for center_gate, traces in all_traces_dict.items():
            label = 0  # Ù‡Ù…ÛŒØ´Ù‡ 0 Ú†ÙˆÙ† ØªØ±ÙˆØ¬Ø§Ù†ÛŒ Ø¯Ø± Ú©Ø§Ø± Ù†ÛŒØ³Øª
            for trace in traces:
                labeled_trace_data.append({
                    'trace': trace,
                    'label': label,
                    'gate': center_gate,
                    'circuit': circuit_name
                })

    except Exception as e:
        return (False, f"Processing Error: {e}")

    # --- 5. Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ JSON ---
    try:
        with open(json_output_file, 'w', encoding='utf-8') as f:
            json.dump(labeled_trace_data, f, indent=2)
    except Exception as e:
        return (False, f"JSON Save Error: {e}")

    return (True, f"Success (Saved {len(labeled_trace_data)} traces and 1 graph)")


# --- ØªØ§Ø¨Ø¹ main Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯ ---
def main():
    DATASET_ROOT = "../Dataset"
    target_folders = ["TRIT-TC/original_designs", "TRIT-TS/original_designs"]

    print("ğŸš€ Processing Original Designs (Saves Graph + Traces)...")
    print(f"Ignoring .spf files, processing only .v files.")

    files_to_process = []
    for target in target_folders:
        path_pattern = os.path.join(DATASET_ROOT, target, "*.v")
        files_found = glob.glob(path_pattern)
        files_to_process.extend(files_found)

    if not files_to_process:
        print("Error: No .v files found in original_designs folders.")
        return

    total_files = len(files_to_process)
    print(f"Found {total_files} original .v files to process.")

    success_count = 0
    fail_count = 0
    failed_files_log = []
    start_time = time.time()

    for i, file_path in enumerate(files_to_process):
        rel_path = os.path.relpath(file_path)
        print(f"[{i + 1}/{total_files}] Processing: {rel_path}...", end=" ", flush=True)
        status, message = process_original_file(file_path)
        if status:
            print(f"âœ… {message}")
            success_count += 1
        else:
            print(f"âŒ FAILED. Reason: {message}")
            fail_count += 1
            failed_files_log.append((rel_path, message))

    end_time = time.time()

    print("\n" + "=" * 50)
    print("ğŸ Original Designs Processing Finished")
    print("=" * 50)
    print(f"Total Time: {end_time - start_time:.2f} seconds")
    print(f"Total Files Processed: {total_files}")
    print(f"âœ… Successful: {success_count}")
    print(f"âŒ Failed: {fail_count}")

    if fail_count > 0:
        print("Failed Files Report:")
        for file, reason in failed_files_log:
            print(f"  - {file}\n    Reason: {reason}")


if __name__ == "__main__":
    main()