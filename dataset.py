#
# dataset.py
# (ÙØ§Ø² 3: Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ PyTorch)
#
import json
import torch
import numpy as np
from torch.utils.data import Dataset
from gensim.models import KeyedVectors
from tqdm import tqdm
import os

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
LABELED_DATA_FILE = "labeled_traces_BALANCED.jsonl"
EMBEDDING_FILE = "net2vec.vectors"
EMBEDDING_DIM = 100  # Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ÙØ§ÛŒÙ„ net2vec.vectors Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
LOGIC_LEVEL = 4
# Ø·ÙˆÙ„ Ø±Ø¯ÛŒØ§Ø¨ÛŒ (trace) Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§Ù„Ù‡ 2*ll-1 Ø§Ø³Øª
MAX_TRACE_LENGTH = (2 * LOGIC_LEVEL) - 1  # (2*4-1 = 7)


# -----------------

class TrojanDataset(Dataset):
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Dataset Ø³ÙØ§Ø±Ø´ÛŒ PyTorch Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª Ù…ØªØ¹Ø§Ø¯Ù„.
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ø¯ÛŒØ³Ú© Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ Ùˆ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """

    def __init__(self, data_file, embedding_file):
        if not os.path.exists(data_file):
            raise FileNotFoundError(f"âŒ ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§Ø³Øª {data_file} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        if not os.path.exists(embedding_file):
            raise FileNotFoundError(f"âŒ ÙØ§ÛŒÙ„ Embedding {embedding_file} ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        print("--- 1. Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Net2Vec (Embeddings)...")
        # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§
        # (Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú© Ø§Ø³Øª Ùˆ Ø¨Ù‡ Ø±Ø§Ø­ØªÛŒ Ø¯Ø± Ø±Ù… Ø¬Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        self.embeddings = KeyedVectors.load_word2vec_format(embedding_file)
        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± ØµÙØ± Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù†ÛŒØ³ØªÙ†Ø¯ (padding)
        self.zero_vector = np.zeros(EMBEDDING_DIM).astype(np.float32)
        print("âœ… ... Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")

        print(f"--- 2. Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª Ù…ØªØ¹Ø§Ø¯Ù„ {data_file}...")
        # 2. Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒØ¯Ø§Ø±
        # (ÙØ§ÛŒÙ„ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ Ú©ÙˆÚ†Ú© Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø±Ù… 16 Ú¯ÛŒÚ¯Ø§Ø¨Ø§ÛŒØªÛŒ Ø¬Ø§ Ø´ÙˆØ¯)
        self.data = []
        with open(data_file, 'r', encoding='utf-8') as f:
            for line in tqdm(f, desc="ğŸ“Š Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª Ù…ØªØ¹Ø§Ø¯Ù„"):
                try:
                    self.data.append(json.loads(line))
                except json.JSONDecodeError:
                    pass  # Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ø®Ø·ÙˆØ· Ø®Ø±Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ

        print(f"âœ… ... {len(self.data):,} Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        print("--- Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ ---")

    def __len__(self):
        """ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
        return len(self.data)

    def __getitem__(self, idx):
        """
        ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ ÙˆØ§Ø­Ø¯ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ†Ø¯Ú©Ø³ (idx) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
        """
        # 1. Ø¢ÛŒØªÙ… Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø¯Ø± Ø±Ù… Ø¨Ø±Ø¯Ø§Ø±
        item = self.data[idx]
        trace_words = item['trace']
        label = item['label']
        gate = item['gate']  # Ø¨Ø±Ø§ÛŒ ÙØ§Ø² 4 (Ø±Ø§ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ) Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØ´ÙˆØ¯

        # 2. Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ù…Ø§ØªØ±ÛŒØ³ ØµÙØ± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø±Ø¯ÛŒØ§Ø¨ÛŒ
        # Ø´Ú©Ù„ Ù…Ø§ØªØ±ÛŒØ³: (7, 100) -> 7 Ú©Ù„Ù…Ù‡ØŒ Ù‡Ø± Ú©Ø¯Ø§Ù… 100 Ø¨Ø¹Ø¯
        trace_tensor_data = np.zeros((MAX_TRACE_LENGTH, EMBEDDING_DIM), dtype=np.float32)

        # 3. ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„Ù…Ø§Øª Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± (Vectorization)
        for i, word in enumerate(trace_words):
            if i >= MAX_TRACE_LENGTH:
                break  # Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø±Ø§ Ù‚Ø·Ø¹ Ú©Ù†

            # Ø§Ú¯Ø± Ú©Ù„Ù…Ù‡ Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨ÙˆØ¯ØŒ Ø¨Ø±Ø¯Ø§Ø± Ø¢Ù† Ø±Ø§ Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡
            if word in self.embeddings:
                trace_tensor_data[i] = self.embeddings[word]
            # Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø¨Ø±Ø¯Ø§Ø± ØµÙØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯ (padding)

        return {
            "trace_tensor": torch.tensor(trace_tensor_data, dtype=torch.float32),
            "label": torch.tensor(label, dtype=torch.long),
            "gate": gate  # Ù†Ø§Ù… Ú¯ÛŒØª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ø´ØªÙ‡â€ŒØ§ÛŒ Ø¹Ø¨ÙˆØ± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
        }


# -----------------
# (Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§Ø³Øª)
if __name__ == "__main__":
    print("--- ğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øª TrojanDataset ---")

    try:
        dataset = TrojanDataset(LABELED_DATA_FILE, EMBEDDING_FILE)

        print(f"\nØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(dataset):,}")

        # ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¨Ø±Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
        sample = dataset[0]

        print("\n--- Ù†Ù…ÙˆÙ†Ù‡ Ø§ÙˆÙ„ Ø¯ÛŒØªØ§Ø³Øª ---")
        print(f"Gate: {sample['gate']}")
        print(f"Label: {sample['label']}")
        print(f"Tensor Shape: {sample['trace_tensor'].shape}")
        print("âœ… Ø§Ø³Ú©Ø±ÛŒÙ¾Øª dataset.py Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")

    except FileNotFoundError as e:
        print(e)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø­ÛŒÙ† ØªØ³Øª: {e}")