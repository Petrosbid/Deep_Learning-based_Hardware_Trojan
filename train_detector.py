#
# train_detector.py
# (ูุงุฒ 3: ุงุณฺฉุฑูพุช ุงุตู ุขููุฒุด ูุฏู LSTM)
#
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import time

# ูุงุฑุฏ ฺฉุฑุฏู ฺฉูุงุณโูุง ุณูุงุฑุด
from dataset import TrojanDataset, LABELED_DATA_FILE, EMBEDDING_FILE
from model import TrojanLSTM

# --- ุชูุธูุงุช ---
BATCH_SIZE = 32  #
LEARNING_RATE = 0.001
NUM_EPOCHS = 5  #
TRAIN_SPLIT = 0.8  # 80% ุจุฑุง ุขููุฒุดุ 20% ุจุฑุง ุงุนุชุจุงุฑุณูุฌ
OUTPUT_MODEL_FILE = "trojan_detector.pth"


# -----------------

def main():
    start_time = time.time()

    # 1. ุจุฑุฑุณ ู ุชูุธู ุฏุณุชฺฏุงู (GPU ุง CPU)
    # (ุงุฒ ฺฏุฑุงูฺฉ 3050 Ti ุดูุง ุงุณุชูุงุฏู ุฎูุงูุฏ ฺฉุฑุฏ)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"--- ๐ ุฏุฑ ุญุงู ุงุณุชูุงุฏู ุงุฒ ุฏุณุชฺฏุงู: {device} ---")
    if device.type == 'cuda':
        print(f"ูุงู GPU: {torch.cuda.get_device_name(0)}")

    # 2. ุจุงุฑฺฏุฐุงุฑ ุฏุชุงุณุช (ุงุฒ dataset.py)
    try:
        full_dataset = TrojanDataset(LABELED_DATA_FILE, EMBEDDING_FILE)
    except FileNotFoundError as e:
        print(e)
        return

    # 3. ุชูุณู ุฏุงุฏูโูุง ุจู ุขููุฒุด (Train) ู ุงุนุชุจุงุฑุณูุฌ (Validation)
    total_size = len(full_dataset)
    train_size = int(total_size * TRAIN_SPLIT)
    val_size = total_size - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    print(f"\n--- ๐ ุชูุณู ุฏุชุงุณุช ---")
    print(f"ฺฉู ูููููโูุง: {total_size:,}")
    print(f"ูููููโูุง ุขููุฒุด (Train): {len(train_dataset):,}")
    print(f"ูููููโูุง ุงุนุชุจุงุฑุณูุฌ (Validation): {len(val_dataset):,}")

    # 4. ุณุงุฎุช DataLoader ูุง
    # DataLoader ุฏุงุฏูโูุง ุฑุง ุฏุฑ ุฏุณุชูโูุง (Batch) 32 ุชุง ุจู GPU ูโูุฑุณุชุฏ
    # (ูุง ุฏฺฏุฑ ุจู Upsampling/Downsampling ูุงุฒ ูุฏุงุฑู ฺูู ุฏุชุงุณุช ุงุฒ ูุจู ูุชุนุงุฏู ุงุณุช)
    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    # 5. ููุฏุงุฑุฏู ุงููู ูุฏูุ ุชุงุจุน ูุฒูู ู ุจูููโุณุงุฒ
    model = TrojanLSTM().to(device)
    criterion = nn.CrossEntropyLoss()  #
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    print("\n--- ๐๏ธ ุดุฑูุน ุขููุฒุด ูุฏู LSTM ---")

    best_val_accuracy = 0.0  # ุจุฑุง ุฐุฎุฑู ุจูุชุฑู ูุฏู

    # 6. ุญููู ุขููุฒุด
    for epoch in range(NUM_EPOCHS):
        start_epoch_time = time.time()

        # --- ุจุฎุด ุขููุฒุด ---
        model.train()  # ูุฏู ุฑุง ุฏุฑ ุญุงูุช ุขููุฒุด ูุฑุงุฑ ุจุฏู
        train_loss = 0.0
        train_corrects = 0

        # ุงุณุชูุงุฏู ุงุฒ tqdm ุจุฑุง ููุงุฑ ูพุดุฑูุช ุขููุฒุด
        for batch in tqdm(train_loader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS} [Train]"):
            traces = batch['trace_tensor'].to(device)
            labels = batch['label'].to(device)

            # 1. ุตูุฑ ฺฉุฑุฏู ฺฏุฑุงุฏุงูโูุง
            optimizer.zero_grad()

            # 2. Forward pass
            outputs = model(traces)
            loss = criterion(outputs, labels)

            # 3. Backward pass ู ุจูููโุณุงุฒ
            loss.backward()
            optimizer.step()

            # ูุญุงุณุจู ุขูุงุฑ
            train_loss += loss.item() * traces.size(0)
            _, preds = torch.max(outputs, 1)
            train_corrects += torch.sum(preds == labels.data)

        # --- ุจุฎุด ุงุนุชุจุงุฑุณูุฌ ---
        model.eval()  # ูุฏู ุฑุง ุฏุฑ ุญุงูุช ุงุฑุฒุงุจ ูุฑุงุฑ ุจุฏู (Dropout ุบุฑูุนุงู ูโุดูุฏ)
        val_loss = 0.0
        val_corrects = 0

        with torch.no_grad():  # ูุญุงุณุจุงุช ฺฏุฑุงุฏุงู ุฑุง ุฎุงููุด ฺฉู
            for batch in tqdm(val_loader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS} [Val]  "):
                traces = batch['trace_tensor'].to(device)
                labels = batch['label'].to(device)

                outputs = model(traces)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * traces.size(0)
                _, preds = torch.max(outputs, 1)
                val_corrects += torch.sum(preds == labels.data)

        # --- ฺุงูพ ูุชุงุฌ ุฏูุฑู ---
        epoch_time = time.time() - start_epoch_time
        avg_train_loss = train_loss / len(train_dataset)
        avg_train_acc = train_corrects.double() / len(train_dataset)
        avg_val_loss = val_loss / len(val_dataset)
        avg_val_acc = val_corrects.double() / len(val_dataset)

        print(f"\nEpoch {epoch + 1}/{NUM_EPOCHS} (Time: {epoch_time:.2f}s)")
        print(f"  Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f}")
        print(f"  Val   Loss: {avg_val_loss:.4f} | Val   Acc: {avg_val_acc:.4f}")

        # ุฐุฎุฑู ุจูุชุฑู ูุฏู (ูุฏู ฺฉู ุจุงูุงุชุฑู ุฏูุช ุงุนุชุจุงุฑุณูุฌ ุฑุง ุฏุงุฑุฏ)
        if avg_val_acc > best_val_accuracy:
            best_val_accuracy = avg_val_acc
            torch.save(model.state_dict(), OUTPUT_MODEL_FILE)
            print(f"  โจ ูุฏู ุจูุชุฑ ูพุฏุง ุดุฏ! ุฏุฑ {OUTPUT_MODEL_FILE} ุฐุฎุฑู ุดุฏ.")

    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print("๐ ูุงุฒ 3 (ุขููุฒุด) ุจุง ููููุช ฺฉุงูู ุดุฏ")
    print("=" * 50)
    print(f"โฑ๏ธ ุฒูุงู ฺฉู ุขููุฒุด: {(total_time) / 60:.2f} ุฏููู")
    print(f"๐ฏ ุจูุชุฑู ุฏูุช ุงุนุชุจุงุฑุณูุฌ: {best_val_accuracy:.4f}")
    print(f"๐พ ูุฏู ููุง ุฏุฑ {OUTPUT_MODEL_FILE} ุฐุฎุฑู ุดุฏ.")
    print("\nโ ุดูุง ุงฺฉููู ุขูุงุฏู ูุฑูุฏ ุจู ูุงุฒ 4 (ุงุฑุฒุงุจ ููุง ู ุฑุฃโฺฏุฑ) ูุณุชุฏ.")


if __name__ == "__main__":
    main()